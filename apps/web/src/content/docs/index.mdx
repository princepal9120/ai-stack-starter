---
title: Introduction
description: Build production-ready AI applications with Next.js, TypeScript, and modern tooling.
---

AI Stack is a full-stack framework for building AI-powered applications. It provides authentication, database integration, vector storage, and LLM connectivity out of the box.

## How to use the docs

The docs are organized into 3 sections:

- **Getting Started**: Set up your first project
- **Guides**: Learn specific features in depth
- **Reference**: Detailed configuration options

Use the sidebar to navigate, or press `Ctrl+K` to search.

## Quick Start

### Requirements

- Node.js 18 or later
- Git

### Create a project

```bash
npx create-ai-stack-starter@latest
```

The CLI will prompt you to choose:

- **Architecture**: Next.js, FastAPI + Next.js, or TypeScript backend
- **Database**: Neon, Supabase, Turso, or SQLite
- **Authentication**: Better Auth, NextAuth, Clerk, or none
- **LLM Provider**: OpenAI, Anthropic, or Novita

### Start development

```bash
cd my-app
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to see your application.

## Skip prompts

Use `--yes` to scaffold with defaults:

```bash
npx create-ai-stack-starter@latest my-app --yes
```

Or specify options directly:

```bash
npx create-ai-stack-starter@latest my-app \
  --architecture nextjs \
  --database neon \
  --auth better-auth \
  --llm openai
```

See [CLI Options](/docs/cli/options) for the full list of flags.

## Next steps

- [Project Structure](/docs/project-structure) - Understand the generated files
- [LLM Providers](/docs/guides/llm-providers) - Connect to OpenAI, Anthropic, or local models
- [RAG Pipeline](/docs/guides/rag-pipeline) - Build retrieval-augmented generation
- [Deployment](/docs/guides/deployment) - Deploy to Vercel, Docker, or Kubernetes
